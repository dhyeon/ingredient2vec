{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import GensimModels\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import Config\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "train = Config.path_culture\n",
    "feat_dim = 10\n",
    "\n",
    "gensimLoader = GensimModels.GensimModels()\n",
    "model_loaded = gensimLoader.load_word2vec(path=Config.path_embeddings_ingredients)\n",
    "\n",
    "cult2id = {}\n",
    "id2cult = []\n",
    "comp2id = {'Nan':0}\n",
    "id2comp = ['Nan']\n",
    "comp2cnt = {'Nan':0}\n",
    "\n",
    "train_cult = []\n",
    "train_comp = []\n",
    "train_comp_len = []\n",
    "\n",
    "comp_thr = 5 \n",
    "max_comp_cnt = 0 \n",
    "filtred_comp = 0 \n",
    "\n",
    "train_f = open(train, 'r')\n",
    "lines = train_f.readlines()[4:]\n",
    "random.shuffle(lines)\n",
    "train_thr = int(len(lines) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build composer dictionary...\n"
     ]
    }
   ],
   "source": [
    "print \"Build composer dictionary...\"\n",
    "for i, line in enumerate(lines):\n",
    "\n",
    "    tokens = line.strip().split(',')\n",
    "    culture = tokens[0]\n",
    "    composers = tokens[1:]\n",
    "\n",
    "    if cult2id.get(culture) is None:\n",
    "        cult2id[culture] = len(cult2id)\n",
    "        id2cult.append(culture)\n",
    "\n",
    "    if comp_thr > len(composers):\n",
    "        filtred_comp += 1\n",
    "        continue\n",
    "\n",
    "    #if max_comp_cnt < len(composers):\n",
    "    #    max_comp_cnt = len(composers)\n",
    "\n",
    "    for composer in composers:\n",
    "        if comp2id.get(composer) is None:\n",
    "            comp2id[composer] = len(comp2id)\n",
    "            id2comp.append(composer)\n",
    "            comp2cnt[composer] = 0.\n",
    "        comp2cnt[composer] += 1\n",
    "\n",
    "    train_cult.append(cult2id.get(culture))\n",
    "    train_comp.append([comp2id.get(composer) for composer in composers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in train_comp:\n",
    "    train_comp_len.append(len(comp))\n",
    "    if len(comp) < max_comp_cnt:\n",
    "        comp += [0]*(max_comp_cnt - len(comp))\n",
    "        \n",
    "f = open('ingr_engine.csv', 'wb')\n",
    "wr = csv.writer(f)\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "wv = model_loaded.wv\n",
    "w = model_loaded.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print [model_loaded[idx] for idx in w]\n",
    "for i, idx in enumerate(w):\n",
    "    if idx not in id2comp:\n",
    "        wr.writerow([i, idx, False])\n",
    "    else:\n",
    "        wr.writerow([i, idx, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861271.0\n"
     ]
    }
   ],
   "source": [
    "total_comp = 0.\n",
    "for cnt in comp2cnt.values():\n",
    "    total_comp += cnt\n",
    "print total_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added cnt : 547\n",
      "unk cnt : 3098 in 3945\n",
      "call cnt : 628219.0 in 861271.0\n",
      "filtered composer count is 9498\n"
     ]
    }
   ],
   "source": [
    "mu, sigma = 0, 1\n",
    "compid2vec = []\n",
    "unk_cnt = 0\n",
    "add_cnt = 0\n",
    "call_cnt = 0.\n",
    "for idx, comp in enumerate(id2comp):\n",
    "    if comp in wv:\n",
    "        wr.writerow([idx, comp, comp2cnt[comp]/total_comp*100, True])\n",
    "        compid2vec.append(model_loaded[comp])\n",
    "        call_cnt += comp2cnt[comp]\n",
    "    elif wnl.lemmatize(comp) in wv:\n",
    "        wr.writerow([idx, comp, comp2cnt[comp]/total_comp*100, 'Modified'])\n",
    "        compid2vec.append(model_loaded[wnl.lemmatize(comp)])\n",
    "        call_cnt += comp2cnt[comp]\n",
    "        add_cnt += 1\n",
    "    elif comp.rstrip().split('_')[-1] in wv:\n",
    "        wr.writerow([idx, comp, comp2cnt[comp]/total_comp*100, 'Modified'])\n",
    "        compid2vec.append(model_loaded[comp.rstrip().split('_')[-1]])\n",
    "        call_cnt += comp2cnt[comp]\n",
    "        add_cnt += 1\n",
    "    elif wnl.lemmatize(comp.rstrip().split('_')[-1]) in wv:\n",
    "        wr.writerow([idx, comp, comp2cnt[comp]/total_comp*100, 'Modified'])\n",
    "        compid2vec.append(model_loaded[wnl.lemmatize(comp.rstrip().split('_')[-1])])\n",
    "        call_cnt += comp2cnt[comp]\n",
    "        add_cnt += 1    \n",
    "    else:\n",
    "        wr.writerow([idx, comp, comp2cnt[comp]/total_comp*100, False])\n",
    "        compid2vec.append(np.random.normal(mu, sigma, feat_dim))\n",
    "        unk_cnt += 1\n",
    "        \n",
    "f.close()\n",
    "print \"added cnt :\", add_cnt\n",
    "print \"unk cnt :\", unk_cnt, \"in\", len(id2comp)\n",
    "print \"call cnt :\", call_cnt, \"in\", total_comp\n",
    "print \"filtered composer count is\", filtred_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
