{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Anology Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def load_ingredients(path):\n",
    "    ingredients = {}\n",
    "    ingredients_list = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line[0] == '#':\n",
    "                pass\n",
    "            else:\n",
    "                line_split = line.rstrip().split('\\t')\n",
    "                ingredients_id = line_split[0]\n",
    "                ingredients_list = line_split[1:]\n",
    "                ingredients[ingredients_id] = ingredients_list\n",
    "    return ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = '..' + os.sep + 'data'\n",
    "path_ingr_info = path_data + os.sep + 'scientific_report' + os.sep + 'ingr_info.tsv'\n",
    "ingredients = load_ingredients(path_ingr_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredients_list = []\n",
    "for ingr_id in ingredients:\n",
    "    ingredients_list.append(ingredients[ingr_id][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_ingr_list = [\"flower\",\"root\",\"tree\",\"leaf\",\"seed\",\"peel\",\"grass\"]\n",
    "\n",
    "\n",
    "for target_ingr in target_ingr_list:\n",
    "    #print target_ingr\n",
    "    \n",
    "    target_list = []\n",
    "    # all ingredients to extract target ingredients\n",
    "    for ingr in ingredients_list:\n",
    "        if target_ingr in ingr:\n",
    "            target_list.append(ingr)\n",
    "    #print target_list\n",
    "\n",
    "    # target ingrdients\n",
    "    for target in target_list:\n",
    "        target_split = target.split(\"_\")\n",
    "        \n",
    "        if target_split[-1] == \"oil\":\n",
    "            continue\n",
    "        try:\n",
    "            target_split.remove(target_ingr)\n",
    "        except ValueError :  # 에러 종류\n",
    "            continue\n",
    "\n",
    "        target_combined = \"_\".join(target_split)\n",
    "\n",
    "        if target_combined in ingredients_list:\n",
    "            print \"%s\\t%s\" % (target_combined, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anology Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from utils import DataLoader, GensimModels, DataPlotter\n",
    "gensimLoader = GensimModels.GensimModels()\n",
    "path_results = \"..\" + os.sep + \"results\"\n",
    "path_embeddings_ingredients = path_results + os.sep + 'embeddings' + os.sep + \"embeddings_ingredients_f-5_rs-True_ns-50_charemb-True_dim50.bin\"\n",
    "model = gensimLoader.load_word2vec(path=path_embeddings_ingredients)\n",
    "\n",
    "# model.wv.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "# orange + citrus_oil - citrus_flower_oil = orange_flower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_data = '..' + os.sep + 'data'\n",
    "path_ingr_anol = path_data + os.sep + 'ingredient-anology-4.txt'\n",
    "\n",
    "anology_dict = {}\n",
    "anology_list = []\n",
    "\n",
    "f_origin = open(path_ingr_anol, 'r')\n",
    "#whole file\n",
    "for line_origin in f_origin:\n",
    "    if line_origin[0] == ':':\n",
    "        continue\n",
    "    #whole file 2\n",
    "    f_target = open(path_ingr_anol, 'r')\n",
    "    for line_target in f_target:\n",
    "        if line_target[0] == \":\":\n",
    "            continue\n",
    "            \n",
    "        line_origin_split = line_origin.rstrip().split(\"\\t\")\n",
    "        line_target_split = line_target.rstrip().split(\"\\t\")\n",
    "\n",
    "        if line_origin_split == line_target_split:\n",
    "            continue\n",
    "        \n",
    "        anology_list.append(line_origin_split + line_target_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':', 'cooked-ingredients', '\"smoked\",\"boiled\",\"grilled\",\"dried\",\"raw\"']\n",
      "\n",
      "Total Number of Test Sets: 1406\n",
      "Top1 Accuracy: 484, 34.423898%\n",
      "Top5 Accuracy: 919, 65.362731%\n",
      "Top10 Accuracy: 1095, 77.880512%\n",
      "Top50 Accuracy: 1294, 92.034139%\n",
      "\n",
      "\n",
      "[':', 'partof-ingredients', '\"flower\",\"root\",\"tree\",\"leaf\",\"seed\",\"peel\",\"grass\"']\n",
      "\n",
      "Total Number of Test Sets: 2256\n",
      "Top1 Accuracy: 2, 0.088652%\n",
      "Top5 Accuracy: 13, 0.576241%\n",
      "Top10 Accuracy: 19, 0.842199%\n",
      "Top50 Accuracy: 55, 2.437943%\n",
      "\n",
      "\n",
      "[':', 'extracted-ingredients', '\"oil\",\"juice\"']\n",
      "\n",
      "Total Number of Test Sets: 35910\n",
      "Top1 Accuracy: 712, 1.982735%\n",
      "Top5 Accuracy: 956, 2.662211%\n",
      "Top10 Accuracy: 1021, 2.843219%\n",
      "Top50 Accuracy: 1160, 3.230298%\n",
      "\n",
      "\n",
      "[':', 'local-ingredients', '\"japanese_,\"chinese_,\"california_,\"thai_,\"spanish_,\"asian_,\"ethiopian_,\"american_\"']\n",
      "\n",
      "Total Number of Test Sets: 1056\n",
      "Top1 Accuracy: 37, 3.503788%\n",
      "Top5 Accuracy: 101, 9.564394%\n",
      "Top10 Accuracy: 119, 11.268939%\n",
      "Top50 Accuracy: 136, 12.878788%\n",
      "\n",
      "\n",
      "\n",
      "Total Number of Test Sets: 40628\n",
      "Top1 Accuracy: 1235, 3.039776%\n",
      "Top5 Accuracy: 1989, 4.895638%\n",
      "Top10 Accuracy: 2254, 5.547898%\n",
      "Top50 Accuracy: 2645, 6.510288%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_data = '..' + os.sep + 'data'\n",
    "path_ingr_anology_test = path_data + os.sep + 'ingredient-anology-test.txt'\n",
    "\n",
    "with open(path_ingr_anology_test, 'r') as f:\n",
    "    anology_list = []\n",
    "    anology_list_all = []\n",
    "    for line in f:\n",
    "        line_split = line.split()\n",
    "        anology_list.append(line_split)\n",
    "        \n",
    "        if line[0] != \":\" and line[0] != \"#\":\n",
    "            anology_list_all.append(line_split)\n",
    "        \n",
    "        if line[0] == '#':\n",
    "            print anology_list[0]\n",
    "            \n",
    "            analogy_test(model, anology_list[1:-1])\n",
    "            \n",
    "            anology_list = []\n",
    "        \n",
    "    analogy_test(model, anology_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_test(word_vectors, anology_list):\n",
    "    top1 = 0\n",
    "    top5 = 0\n",
    "    top10 = 0\n",
    "    top50 = 0\n",
    "\n",
    "    for anology in anology_list:\n",
    "        word1 = anology[0] # positive\n",
    "        word1_1 = anology[1] # answer\n",
    "        word2 = anology[2] # negative\n",
    "        word2_1 = anology[3] # positive\n",
    "\n",
    "        try:\n",
    "            list_most_similar = word_vectors.most_similar(positive=[word1_1, word2], negative=[word1], topn = 50)\n",
    "            #list_most_similar_cosmul = word_vectors.most_similar_cosmul(positive=[word1, word2_1], negative=[word2], topn = 30)\n",
    "\n",
    "        except KeyError as ke:\n",
    "            #print ke\n",
    "            continue\n",
    "            \n",
    "        #print \"\\nIngredient Analogy Test\"\n",
    "        #print \"%s + %s - %s = %s\" % (word1, word2_1, word2, word1_1)\n",
    "        for ix, dic in enumerate(list_most_similar):\n",
    "            word = dic[0]\n",
    "            score = dic[1]\n",
    "\n",
    "            if word2_1 == word:\n",
    "                if ix+1 == 1:\n",
    "                    top1 += 1\n",
    "                if ix+1 <= 5:\n",
    "                    top5 += 1\n",
    "                if ix+1 <= 10:\n",
    "                    top10 += 1\n",
    "                if ix+1 <= 50:\n",
    "                    top50 += 1\n",
    "                \n",
    "                #print \"\\nIngredient Analogy Test\"\n",
    "                #print \"%s + %s - %s = %s\" % (word1_1, word2, word1, word2_1)\n",
    "                #print word, score, ix+1\n",
    "\n",
    "    num_test_sets = len(anology_list)\n",
    "    print \"\\nTotal Number of Test Sets:\", num_test_sets\n",
    "    print \"Top1 Accuracy: %d, %f%%\" % (top1, top1/float(num_test_sets)*100)\n",
    "    print \"Top5 Accuracy: %d, %f%%\" % (top5, top5/float(num_test_sets)*100)\n",
    "    print \"Top10 Accuracy: %d, %f%%\" % (top10, top10/float(num_test_sets)*100)\n",
    "    print \"Top50 Accuracy: %d, %f%%\\n\\n\" % (top50, top50/float(num_test_sets)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
